# Leaning_from_top_Kagglers
This notebook is dedicated to the homework assignments, sample codes, and final project of the Coursera course :["How to win a data science competition"](https://www.coursera.org/learn/competitive-data-science/quiz/Hwg9B/recap)


You can access all the files for the projects and homeworks [here](https://hub.coursera-notebooks.org/user/mjgtcrdyoihyrxjdsztjpm/tree)

## USeful resources:

The class instructors managed to provide a unique set of resources for different topics. I found them very interesting and very good refreshers. They will be provided here.


### Classifiers:

[Explanation of Random Forest](https://www.datasciencecentral.com/profiles/blogs/random-forests-explained-intuitively)

[Explanation/Demonstration of Gradient Boosting](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)

[Example of kNN](https://www.analyticsvidhya.com/blog/2014/10/introduction-k-neighbours-algorithm-clustering/)

[Link to Machine Learning Packages](https://www.coursera.org/learn/competitive-data-science/supplement/AgAOD/additional-materials-and-links)


### Feature Engineering:

[How to get good at feature engineering](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)

[Featuer Engineering](https://www.quora.com/What-are-some-best-practices-in-Feature-Engineering)

[Text Feature Engineering](https://www.coursera.org/learn/competitive-data-science/supplement/BGgHF/additional-material-and-links)


### EDA:

[Visualization Tools](https://www.coursera.org/learn/competitive-data-science/supplement/DmpnI/additional-material-and-links)


### Validation:

[Validation in Sklearn](http://scikit-learn.org/stable/modules/cross_validation.html)

[Validation for Competitions](http://www.chioka.in/how-to-select-your-final-models-in-a-kaggle-competitio/)

